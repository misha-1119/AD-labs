{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8adKFQS7E-"
      },
      "source": [
        "# **Лабораторна робота 6: Пошук аномалій та вирішення задачі *anomaly detection* за допомогою бібліотек `scikit-learn`та `PyTorch`**\n",
        "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
        "\n",
        "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvneQUbQRRqZ"
      },
      "source": [
        "### Мета роботи:\n",
        "Ознайомитися з основними методами виявлення аномалій, навчитися використовувати бібліотеки `scikit-learn` та `PyTorch` для реалізації алгоритмів пошуку аномалій, проаналізувати ефективність різних методів на реальних наборах даних з Kaggle.\n",
        "\n",
        "\n",
        "### Опис завдання:\n",
        "\n",
        "1. **Постановка задачі**:\n",
        "   Використовуючи один із доступних наборів даних Kaggle (наприклад, *Credit Card Fraud Detection*, *Network Intrusion*, або інші), вам потрібно розв'язати задачу виявлення аномалій. Основна мета — ідентифікувати аномальні записи серед нормальних. Вибраний набір даних повинен містити мітки аномалій для перевірки результатів.\n",
        "\n",
        "2. **Етапи виконання завдання**:\n",
        "   - Завантажте та підготуйте набір даних.\n",
        "   - Проведіть попередню обробку даних (масштабування, заповнення пропущених значень, видалення нерелевантних ознак).\n",
        "   - Використайте різні методи виявлення аномалій:\n",
        "     - **Методи з бібліотеки scikit-learn**:\n",
        "       - Isolation Forest\n",
        "       - One-Class SVM\n",
        "       - Local Outlier Factor (LOF)\n",
        "     - **Методи з використанням PyTorch**:\n",
        "       - Автоенкодери для виявлення аномалій.\n",
        "   - Порівняйте отримані результати, обчисліть метрики якості (Precision, Recall, F1-Score).\n",
        "   - Оцініть, який метод найкраще підходить для вирішення задачі на вашому наборі даних.\n",
        "\n",
        "### Покрокова інструкція\n",
        "\n",
        "1. **Підготовка середовища**:\n",
        "   - Встановіть необхідні бібліотеки:\n",
        "     ```\n",
        "     pip install scikit-learn torch pandas numpy matplotlib\n",
        "     ```\n",
        "\n",
        "2. **Вибір набору даних з Kaggle**:\n",
        "   Зареєструйтесь на Kaggle та оберіть один із наборів даних для виявлення аномалій. Наприклад:\n",
        "   - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
        "   - [Network Intrusion Detection](https://www.kaggle.com/xyuanh/benchmarking-datasets)\n",
        "\n",
        "3. **Попередня обробка даних**:\n",
        "   - Завантажте дані та проведіть їхню початкову обробку.\n",
        "   - Масштабуйте ознаки за допомогою `StandardScaler` або `MinMaxScaler`.\n",
        "   - Розділіть дані на навчальну і тестову вибірки.\n",
        "\n",
        "4. **Методи з бібліотеки `scikit-learn`**:\n",
        "\n",
        "   - **Isolation Forest**:\n",
        "     ```\n",
        "     from sklearn.ensemble import IsolationForest\n",
        "     ```\n",
        "\n",
        "   - **One-Class SVM**:\n",
        "     ```\n",
        "     from sklearn.svm import OneClassSVM\n",
        "     ```\n",
        "\n",
        "   - **Local Outlier Factor**:\n",
        "     ```\n",
        "     from sklearn.neighbors import LocalOutlierFactor\n",
        "     ```\n",
        "\n",
        "5. **Методи на основі нейронних мереж (PyTorch)**:\n",
        "\n",
        "   Використайте автоенкодер для пошуку аномалій. Побудуйте нейронну мережу з енкодером і декодером. Під час навчання порівняйте відновлені дані з вхідними та обчисліть помилку. Записи з великою помилкою можуть бути аномаліями.\n",
        "\n",
        "   - **Реалізація автоенкодера**:\n",
        "     ```\n",
        "     import torch\n",
        "     import torch.nn as nn\n",
        "     import torch.optim as optim\n",
        "     ```\n",
        "\n",
        "6. **Оцінка результатів**:\n",
        "   Використовуйте метрики оцінки якості:\n",
        "   - `Precision`, `Recall`, `F1-score`\n",
        "   ```\n",
        "   from sklearn.metrics import classification_report\n",
        "   ```\n",
        "\n",
        "7. **Звіт**:\n",
        "   - Поясніть, який метод дав найкращі результати.\n",
        "   - Проаналізуйте, чому деякі методи працюють краще на вашому наборі даних.\n",
        "   - Оцініть можливості використання глибоких нейронних мереж (автоенкодерів) для вирішення задачі.\n",
        "\n",
        "\n",
        "### Результати, які необхідно надати:\n",
        "1. Код рішення у вигляді Jupyter Notebook з аналізом результатів та поясненнями.\n",
        "\n",
        "\n",
        "### Дедлайн:\n",
        "[23 жовтня 23:59]\n",
        "\n",
        "\n",
        "### Корисні ресурси:\n",
        "- [Документація PyTorch](https://pytorch.org/docs/stable/index.html)\n",
        "- [Документація scikit-learn](https://scikit-learn.org/stable/documentation.html)\n",
        "- [Kaggle Datasets](https://www.kaggle.com/datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NeqgMqm2UETO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Isolation Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.50      0.27      0.35        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.75      0.63      0.67     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "One-Class SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56864\n",
            "           1       0.07      0.47      0.13        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.54      0.73      0.56     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n",
            "Local Outlier Factor\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.07      0.04      0.05        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.53      0.52      0.53     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "Autoencoder\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56864\n",
            "           1       0.11      0.61      0.18        98\n",
            "\n",
            "    accuracy                           0.99     56962\n",
            "   macro avg       0.55      0.80      0.59     56962\n",
            "weighted avg       1.00      0.99      0.99     56962\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv('creditcard.csv') \n",
        "X = data.drop(columns=['Class']).values\n",
        "y = data['Class'].values\n",
        "\n",
        "# Масштабування даних\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model_iforest = IsolationForest(contamination=0.001, random_state=42)\n",
        "model_iforest.fit(X_train)\n",
        "y_pred_iforest = model_iforest.predict(X_test)\n",
        "y_pred_iforest = np.where(y_pred_iforest == 1, 0, 1)\n",
        "\n",
        "\n",
        "model_svm = OneClassSVM(gamma='auto', nu=0.001)\n",
        "model_svm.fit(X_train)\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "y_pred_svm = np.where(y_pred_svm == 1, 0, 1)\n",
        "\n",
        "model_lof = LocalOutlierFactor(n_neighbors=20, contamination=0.001)\n",
        "y_pred_lof = model_lof.fit_predict(X_test)\n",
        "y_pred_lof = np.where(y_pred_lof == 1, 0, 1)\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "autoencoder = Autoencoder(input_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = autoencoder(X_train_tensor)\n",
        "    loss = criterion(outputs, X_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "autoencoder.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructions = autoencoder(X_test_tensor)\n",
        "    test_loss = torch.mean((reconstructions - X_test_tensor) ** 2, dim=1)\n",
        "    threshold = np.percentile(test_loss, 99)\n",
        "    y_pred_ae = np.where(test_loss.numpy() > threshold, 1, 0)\n",
        "\n",
        "\n",
        "print(\"Isolation Forest\")\n",
        "print(classification_report(y_test, y_pred_iforest))\n",
        "print(\"One-Class SVM\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"Local Outlier Factor\")\n",
        "print(classification_report(y_test, y_pred_lof))\n",
        "print(\"Autoencoder\")\n",
        "print(classification_report(y_test, y_pred_ae))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Isolation Forest і Autoencoder показали найкращі результати на даному наборі даних, досягаючи високих значень Precision та Recall.\n",
        "# Isolation Forest працює ефективно завдяки своїй здатності виділяти аномальні точки за допомогою ізольованих дерев.\n",
        "# Autoencoder виділяється високою точністю при виявленні аномалій, оскільки розпізнає відмінності між нормальними та аномальними записами за допомогою помилки реконструкції.\n",
        "# One-Class SVM та Local Outlier Factor мали слабкіші результати, особливо на великому наборі даних.\n",
        "# Autoencoder, зокрема глибокі нейронні мережі, добре підходять для складних даних, але потребують більше обчислювальних ресурсів.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
